{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe98b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\google\\api_core\\_python_version_support.py:246: FutureWarning: You are using a non-supported Python version (3.9.10). Google will not post any further updates to google.api_core supporting this Python version. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\google\\auth\\__init__.py:54: FutureWarning: \n",
      "    You are using a Python version 3.9 past its end of life. Google will update\n",
      "    google-auth with critical bug fixes on a best-effort basis, but not\n",
      "    with any other fixes or features. Please upgrade your Python version,\n",
      "    and then update google-auth.\n",
      "    \n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\google\\oauth2\\__init__.py:40: FutureWarning: \n",
      "    You are using a Python version 3.9 past its end of life. Google will update\n",
      "    google-auth with critical bug fixes on a best-effort basis, but not\n",
      "    with any other fixes or features. Please upgrade your Python version,\n",
      "    and then update google-auth.\n",
      "    \n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional,GlobalAveragePooling1D, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1ab571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36006 samples.\n",
      "  Train samples: 28804\n",
      "    Val samples: 3601\n",
      "   Test samples: 3601\n"
     ]
    }
   ],
   "source": [
    "# 1. Các biến cấu hình\n",
    "DATA_PATH        = 'Data'                # thư mục gốc chứa các folder action\n",
    "LABEL_MAP_PATH   = 'Logs/label_map.json'\n",
    "BATCH_SIZE       = 32\n",
    "AUTOTUNE         = tf.data.AUTOTUNE\n",
    "VAL_SPLIT        = 0.1\n",
    "TEST_SPLIT       = 0.1\n",
    "# 2. Load label_map từ JSON\n",
    "with open(LABEL_MAP_PATH, 'r', encoding='utf-8') as f:\n",
    "    label_map = json.load(f)            # ví dụ: {\"địa chỉ\": 0, \"miến điện\": 1, ...}\n",
    "\n",
    "# 3. Tạo danh sách tất cả các file .npz\n",
    "#    Data structure: Data/<action_name>/*.npz\n",
    "file_pattern = os.path.join(DATA_PATH, '**', '*.npz')\n",
    "all_files = glob.glob(file_pattern, recursive=True)\n",
    "print(f\"Found {len(all_files)} samples.\")\n",
    "\n",
    "train_files, temp_files = train_test_split(\n",
    "    all_files,\n",
    "    test_size=VAL_SPLIT + TEST_SPLIT,  # ví dụ: 0.2 + 0.1 = 0.3\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    stratify=[os.path.basename(p).split('.')[0] for p in all_files]\n",
    ")\n",
    "\n",
    "val_files, test_files = train_test_split(\n",
    "    temp_files,\n",
    "    test_size=TEST_SPLIT / (VAL_SPLIT + TEST_SPLIT),  # ví dụ: 0.1 / 0.3 = 1/3\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    stratify=[os.path.basename(p).split('.')[0] for p in temp_files]\n",
    ")\n",
    "\n",
    "print(f\"  Train samples: {len(train_files)}\")\n",
    "print(f\"    Val samples: {len(val_files)}\")\n",
    "print(f\"   Test samples: {len(test_files)}\")\n",
    "\n",
    "# 4. Hàm parse mỗi file .npz\n",
    "def _load_npz(path):\n",
    "    # path: scalar tf.string tensor\n",
    "    npz_path = path.decode('utf-8')\n",
    "    data = np.load(npz_path)\n",
    "    seq   = data['sequence'].astype(np.float32)   # (60,126)\n",
    "    lbl   = np.int32(data['label'])\n",
    "    return seq, lbl\n",
    "\n",
    "def parse_fn(path):\n",
    "    seq, lbl = tf.numpy_function(\n",
    "        func=_load_npz,\n",
    "        inp=[path],\n",
    "        Tout=[tf.float32, tf.int32]\n",
    "    )\n",
    "    # set shape để TF biết kích thước cố định\n",
    "    seq.set_shape([60, 201])\n",
    "    lbl.set_shape([])\n",
    "    return seq, lbl\n",
    "def make_dataset(file_list, shuffle=False, repeat=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(file_list)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(file_list), reshuffle_each_iteration=True)\n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "    ds = ds.map(parse_fn, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# 6. Tạo train_ds & val_ds\n",
    "train_ds = make_dataset(train_files, shuffle=True, repeat=True)\n",
    "val_ds   = make_dataset(val_files, shuffle=False, repeat=False)\n",
    "test_ds  = make_dataset(test_files, shuffle=False, repeat=False)\n",
    "\n",
    "# 7. Compute steps\n",
    "steps_per_epoch = len(train_files) // BATCH_SIZE\n",
    "validation_steps = len(val_files) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8adb8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(60, 201))\n",
    "\n",
    "# Khối LSTM thứ nhất\n",
    "x = Bidirectional(LSTM(256, return_sequences=True, dropout=0.3))(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Khối LSTM thứ hai\n",
    "x = Bidirectional(LSTM(256, return_sequences=True, dropout=0.3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Khối LSTM thứ ba\n",
    "x = Bidirectional(LSTM(256, dropout=0.3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Các lớp Dense\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Lớp đầu ra\n",
    "outputs = Dense(2764, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "# Biên dịch mô hình\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ae33f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tạo thư mục lưu checkpoint (nếu chưa có)\n",
    "checkpoint_dir = 'Models/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'final_model.keras')\n",
    "\n",
    "# 2. Khởi tạo callbacks\n",
    "callbacks = [\n",
    "    # Lưu mô hình với val_loss thấp nhất\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,  # lưu cả kiến trúc + weights\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Dừng training nếu 5 epoch liên tiếp không cải thiện val_loss\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca557bcb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.0041 - loss: 6.7241\n",
      "Epoch 1: val_loss improved from inf to 5.08210, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1911s\u001b[0m 2s/step - accuracy: 0.0041 - loss: 6.7234 - val_accuracy: 0.0254 - val_loss: 5.0821\n",
      "Epoch 2/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1903s\u001b[0m 2s/step - accuracy: 0.0271 - loss: 5.1634\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.0855 - loss: 4.2056\n",
      "Epoch 3: val_loss improved from 5.08210 to 2.97766, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2003s\u001b[0m 2s/step - accuracy: 0.0855 - loss: 4.2053 - val_accuracy: 0.2511 - val_loss: 2.9777\n",
      "Epoch 4/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1836s\u001b[0m 2s/step - accuracy: 0.1834 - loss: 3.2675\n",
      "Epoch 5/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2920 - loss: 2.5598\n",
      "Epoch 5: val_loss improved from 2.97766 to 1.31618, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2003s\u001b[0m 2s/step - accuracy: 0.2920 - loss: 2.5596 - val_accuracy: 0.6069 - val_loss: 1.3162\n",
      "Epoch 6/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2137s\u001b[0m 2s/step - accuracy: 0.4100 - loss: 1.9795\n",
      "Epoch 7/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4880 - loss: 1.6415\n",
      "Epoch 7: val_loss improved from 1.31618 to 0.78757, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3138s\u001b[0m 3s/step - accuracy: 0.4880 - loss: 1.6414 - val_accuracy: 0.7584 - val_loss: 0.7876\n",
      "Epoch 8/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2004s\u001b[0m 2s/step - accuracy: 0.5727 - loss: 1.3149\n",
      "Epoch 9/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6390 - loss: 1.1001\n",
      "Epoch 9: val_loss improved from 0.78757 to 0.40522, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2400s\u001b[0m 3s/step - accuracy: 0.6390 - loss: 1.1001 - val_accuracy: 0.8633 - val_loss: 0.4052\n",
      "Epoch 10/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2478s\u001b[0m 3s/step - accuracy: 0.6874 - loss: 0.9402\n",
      "Epoch 11/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7200 - loss: 0.8296\n",
      "Epoch 11: val_loss improved from 0.40522 to 0.27369, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2106s\u001b[0m 2s/step - accuracy: 0.7201 - loss: 0.8295 - val_accuracy: 0.9012 - val_loss: 0.2737\n",
      "Epoch 12/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1906s\u001b[0m 2s/step - accuracy: 0.7512 - loss: 0.7347\n",
      "Epoch 13/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7699 - loss: 0.6924\n",
      "Epoch 13: val_loss improved from 0.27369 to 0.21458, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1983s\u001b[0m 2s/step - accuracy: 0.7699 - loss: 0.6924 - val_accuracy: 0.9182 - val_loss: 0.2146\n",
      "Epoch 14/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1939s\u001b[0m 2s/step - accuracy: 0.7972 - loss: 0.6000\n",
      "Epoch 15/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8084 - loss: 0.5637\n",
      "Epoch 15: val_loss improved from 0.21458 to 0.14631, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2078s\u001b[0m 2s/step - accuracy: 0.8084 - loss: 0.5637 - val_accuracy: 0.9495 - val_loss: 0.1463\n",
      "Epoch 16/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2084s\u001b[0m 2s/step - accuracy: 0.8225 - loss: 0.5334\n",
      "Epoch 17/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8324 - loss: 0.4959\n",
      "Epoch 17: val_loss improved from 0.14631 to 0.12790, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2092s\u001b[0m 2s/step - accuracy: 0.8324 - loss: 0.4959 - val_accuracy: 0.9498 - val_loss: 0.1279\n",
      "Epoch 18/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1897s\u001b[0m 2s/step - accuracy: 0.8461 - loss: 0.4551\n",
      "Epoch 19/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8513 - loss: 0.4445\n",
      "Epoch 19: val_loss improved from 0.12790 to 0.09526, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1968s\u001b[0m 2s/step - accuracy: 0.8513 - loss: 0.4446 - val_accuracy: 0.9696 - val_loss: 0.0953\n",
      "Epoch 20/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1877s\u001b[0m 2s/step - accuracy: 0.8484 - loss: 0.4520\n",
      "Epoch 21/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8638 - loss: 0.4042\n",
      "Epoch 21: val_loss improved from 0.09526 to 0.07088, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1965s\u001b[0m 2s/step - accuracy: 0.8638 - loss: 0.4042 - val_accuracy: 0.9757 - val_loss: 0.0709\n",
      "Epoch 22/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1887s\u001b[0m 2s/step - accuracy: 0.8742 - loss: 0.3786\n",
      "Epoch 23/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8793 - loss: 0.3512\n",
      "Epoch 23: val_loss did not improve from 0.07088\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2027s\u001b[0m 2s/step - accuracy: 0.8793 - loss: 0.3512 - val_accuracy: 0.9696 - val_loss: 0.0813\n",
      "Epoch 24/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1969s\u001b[0m 2s/step - accuracy: 0.8851 - loss: 0.3478\n",
      "Epoch 25/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8957 - loss: 0.3112\n",
      "Epoch 25: val_loss did not improve from 0.07088\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1994s\u001b[0m 2s/step - accuracy: 0.8957 - loss: 0.3112 - val_accuracy: 0.9618 - val_loss: 0.0887\n",
      "Epoch 26/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1912s\u001b[0m 2s/step - accuracy: 0.8953 - loss: 0.3157\n",
      "Epoch 27/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9077 - loss: 0.2850\n",
      "Epoch 27: val_loss improved from 0.07088 to 0.05985, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2010s\u001b[0m 2s/step - accuracy: 0.9077 - loss: 0.2850 - val_accuracy: 0.9794 - val_loss: 0.0599\n",
      "Epoch 28/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1919s\u001b[0m 2s/step - accuracy: 0.9025 - loss: 0.2960\n",
      "Epoch 29/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9095 - loss: 0.2780\n",
      "Epoch 29: val_loss did not improve from 0.05985\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2055s\u001b[0m 2s/step - accuracy: 0.9095 - loss: 0.2780 - val_accuracy: 0.9760 - val_loss: 0.0672\n",
      "Epoch 30/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1948s\u001b[0m 2s/step - accuracy: 0.9138 - loss: 0.2691\n",
      "Epoch 31/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9174 - loss: 0.2484\n",
      "Epoch 31: val_loss improved from 0.05985 to 0.04550, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2044s\u001b[0m 2s/step - accuracy: 0.9174 - loss: 0.2485 - val_accuracy: 0.9821 - val_loss: 0.0455\n",
      "Epoch 32/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1981s\u001b[0m 2s/step - accuracy: 0.9190 - loss: 0.2454\n",
      "Epoch 33/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9170 - loss: 0.2604\n",
      "Epoch 33: val_loss did not improve from 0.04550\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2331s\u001b[0m 3s/step - accuracy: 0.9170 - loss: 0.2604 - val_accuracy: 0.9827 - val_loss: 0.0541\n",
      "Epoch 34/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2172s\u001b[0m 2s/step - accuracy: 0.9169 - loss: 0.2608\n",
      "Epoch 35/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9254 - loss: 0.2396\n",
      "Epoch 35: val_loss improved from 0.04550 to 0.04108, saving model to Models/checkpoints\\final_model.keras\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2087s\u001b[0m 2s/step - accuracy: 0.9254 - loss: 0.2396 - val_accuracy: 0.9835 - val_loss: 0.0411\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1962s\u001b[0m 2s/step - accuracy: 0.9324 - loss: 0.2077\n",
      "Epoch 37/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9294 - loss: 0.2226\n",
      "Epoch 37: val_loss did not improve from 0.04108\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2175s\u001b[0m 2s/step - accuracy: 0.9294 - loss: 0.2226 - val_accuracy: 0.9729 - val_loss: 0.0817\n",
      "Epoch 38/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2255s\u001b[0m 3s/step - accuracy: 0.8754 - loss: 0.3881\n",
      "Epoch 43/100\n",
      "\u001b[1m 89/900\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37:56\u001b[0m 3s/step - accuracy: 0.8998 - loss: 0.3206"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a9e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec7778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
